# Data-Analysis-NanoDegree-Project-6
Exploratory-Explanatory Visualisation on Bike Share Data

NYC Bike Share operates Citi Bike program and generates data regarding the program, including trip records, a real time feed of station status and monthly reports. The Citi Bike program data is exclusively generated by the operator NYC Bike Share, a limited liability corporation solely owned by Motivate. The dataset and documentation on the data can be found via this link https://www.citibikenyc.com/system-data.

The data includes (for each month of a year):
- Trip Duration in seconds
- Start Time and Date
- Stop Time and Date
- Start Station Name
- End Station Name
- Station ID
- Station Lat/Long
- Bike ID
- User Type (Customer = 24-hour pass or 3-day pass user; Subscriber = Annual Member)
- Gender (0 = unknown; 1 = male; 2 = female)
- Year of Birth

This data has been processed to remove trips that are taken by staff as they service and inspect the system, trips that are taken to/from any of the “test” stations, and any trips that were below 60 seconds in length (potentially false starts or users trying to re-dock a bike to ensure it's secure).

In this study, we are investigating the NYC bike share data in the year of 2020. Due to the volume of downloads I choose not to do it manually. Instead, I use Beautifulsoup and requests to parse the domain HTML (https://s3.amazonaws.com/tripdata/index.html), and then automate the downloading process with requests and zipfile and save the unziped spreadsheets to the working folder with Pandas' to_csv method.

The downloaded spreadsheets are read in and merged into one big dataframe that holds the record for the whole year. After that, I wrangle the dataframe - remove redundant information, remove any duplicated and NaN data, remove any apparent outliers, modify datatypes to suit, and create additional features for analyses later on.

Python libraries used in this project:

import numpy as np

import pandas as pd

import matplotlib.pyplot as plt

import seaborn as sns

from scipy import stats

import folium

from bs4 import BeautifulSoup as bs

import os

import requests

from zipfile import ZipFile

from io import BytesIO
